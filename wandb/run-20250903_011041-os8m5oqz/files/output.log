2025-09-03 01:10:42,527 | INFO | 📦 Loading model: openai/gpt-oss-20b
`torch_dtype` is deprecated! Use `dtype` instead!
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
2025-09-03 01:10:46,599 | INFO | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|█| 3/3 [00:04<00:00,  1.65
trainable params: 7,962,624 || all params: 20,922,719,808 || trainable%: 0.0381
2025-09-03 01:10:53,035 | INFO | 📊 Loaded 10 problems for continual learning
2025-09-03 01:10:53,035 | INFO | ============================================================
2025-09-03 01:10:53,035 | INFO | 🎯 CONTINUAL LEARNING: Problem 1/10
2025-09-03 01:10:53,036 | INFO | 📋 Problem UID: 6d75e8bb
2025-09-03 01:10:53,036 | INFO | ============================================================
[2025-09-03 01:10:53,199] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2025-09-03 01:10:53,247 | INFO | gcc -pthread -B /home/ubuntu/miniconda3/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/ubuntu/miniconda3/include -fPIC -O2 -isystem /home/ubuntu/miniconda3/include -fPIC -c /tmp/tmpi3nshcjg/test.c -o /tmp/tmpi3nshcjg/test.o
2025-09-03 01:10:53,261 | INFO | gcc -pthread -B /home/ubuntu/miniconda3/compiler_compat /tmp/tmpi3nshcjg/test.o -laio -o /tmp/tmpi3nshcjg/a.out
2025-09-03 01:10:53,415 | INFO | gcc -pthread -B /home/ubuntu/miniconda3/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/ubuntu/miniconda3/include -fPIC -O2 -isystem /home/ubuntu/miniconda3/include -fPIC -c /tmp/tmpymu1spgh/test.c -o /tmp/tmpymu1spgh/test.o
2025-09-03 01:10:53,429 | INFO | gcc -pthread -B /home/ubuntu/miniconda3/compiler_compat /tmp/tmpymu1spgh/test.o -L/usr/local/cuda-12.8 -L/usr/local/cuda-12.8/lib64 -lcufile -o /tmp/tmpymu1spgh/a.out
2025-09-03 01:10:54,438 | INFO | 🎯 Starting training for problem 1...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
  0%|                              | 0/50 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
Caching is incompatible with gradient checkpointing in GptOssDecoderLayer. Setting `past_key_values=None`.
/home/ubuntu/miniconda3/lib/python3.13/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-09-03 01:38:07,310 | INFO | Problem 1 Step 0 Reward: -0.100
2025-09-03 01:38:07,310 | INFO |   Components - Format: -0.10, Size: 0.00, Pixel: 0.00
  2%|▎                | 1/50 [28:08<22:59:15, 1688.88s/it]2025-09-03 02:07:10,375 | INFO | Problem 1 Step 1 Reward: -0.110
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0, 'num_tokens': 26998.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.10000000149011612, 'rewards/reward_function/std': 0.0, 'reward': -0.10000000149011612, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 1.0}
2025-09-03 02:07:10,376 | INFO |   Components - Format: -0.11, Size: 0.00, Pixel: 0.00
  4%|▋                | 2/50 [57:01<22:51:47, 1714.73s/it]2025-09-03 02:36:00,609 | INFO | Problem 1 Step 2 Reward: -0.120
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.000000000000001e-07, 'num_tokens': 53996.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.10999999940395355, 'rewards/reward_function/std': 0.0, 'reward': -0.10999999940395355, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 2.0}
2025-09-03 02:36:00,610 | INFO |   Components - Format: -0.12, Size: 0.00, Pixel: 0.00
  6%|▉              | 3/50 [1:25:57<22:30:52, 1724.53s/it]2025-09-03 03:04:51,965 | INFO | Problem 1 Step 3 Reward: -0.130
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0000000000000002e-06, 'num_tokens': 80994.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.11999999731779099, 'rewards/reward_function/std': 0.0, 'reward': -0.11999999731779099, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 3.0}
2025-09-03 03:04:51,966 | INFO |   Components - Format: -0.13, Size: 0.00, Pixel: 0.00
  8%|█▏             | 4/50 [1:54:42<22:02:09, 1724.56s/it]2025-09-03 03:33:39,601 | INFO | Problem 1 Step 4 Reward: -0.140
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 107992.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.12999999523162842, 'rewards/reward_function/std': 0.0, 'reward': -0.12999999523162842, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 4.0}
2025-09-03 03:33:39,601 | INFO |   Components - Format: -0.14, Size: 0.00, Pixel: 0.00
 10%|█▌             | 5/50 [2:23:27<21:33:24, 1724.54s/it]2025-09-03 04:02:24,741 | INFO | Problem 1 Step 5 Reward: -0.150
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 134990.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.14000000059604645, 'rewards/reward_function/std': 0.0, 'reward': -0.14000000059604645, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 5.0}
2025-09-03 04:02:24,741 | INFO |   Components - Format: -0.15, Size: 0.00, Pixel: 0.00
 12%|█▊             | 6/50 [2:52:12<21:04:48, 1724.73s/it]2025-09-03 04:31:07,594 | INFO | Problem 1 Step 6 Reward: -0.160
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-06, 'num_tokens': 161988.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.15000000596046448, 'rewards/reward_function/std': 0.0, 'reward': -0.15000000596046448, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.0}
2025-09-03 04:31:07,594 | INFO |   Components - Format: -0.16, Size: 0.00, Pixel: 0.00
 14%|██             | 7/50 [3:20:54<20:35:36, 1724.10s/it]2025-09-03 04:59:54,485 | INFO | Problem 1 Step 7 Reward: -0.170
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'num_tokens': 188986.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.1599999964237213, 'rewards/reward_function/std': 0.0, 'reward': -0.1599999964237213, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 7.0}
2025-09-03 04:59:54,486 | INFO |   Components - Format: -0.17, Size: 0.00, Pixel: 0.00
 16%|██▍            | 8/50 [3:49:41<20:07:30, 1725.02s/it]
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5e-06, 'num_tokens': 215984.0, 'completions/mean_length': 12000.0, 'completions/min_length': 12000.0, 'completions/max_length': 12000.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_function/mean': -0.17000000178813934, 'rewards/reward_function/std': 0.0, 'reward': -0.17000000178813934, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 8.0}
