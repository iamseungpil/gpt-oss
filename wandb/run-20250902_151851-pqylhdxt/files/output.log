2025-09-02 15:18:52 | INFO | ðŸ“¦ Loading model: openai/gpt-oss-20b
`torch_dtype` is deprecated! Use `dtype` instead!
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
2025-09-02 15:18:55 | INFO | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|â–ˆ| 3/3 [00:04<00:00,  1.36
trainable params: 7,962,624 || all params: 20,922,719,808 || trainable%: 0.0381
2025-09-02 15:19:02 | INFO | ðŸ“Š Loaded 10 problems for continual learning
2025-09-02 15:19:02 | INFO | ============================================================
2025-09-02 15:19:02 | INFO | ðŸŽ¯ CONTINUAL LEARNING: Problem 1/10
2025-09-02 15:19:02 | INFO | ðŸ“‹ Problem UID: 6d75e8bb
2025-09-02 15:19:02 | INFO | ============================================================
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/ubuntu/gpt-oss/main_hf_trl_dapo_v3.py", line 449, in <module>
[rank0]:     continual_learning_main()
[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~^^
[rank0]:   File "/home/ubuntu/gpt-oss/main_hf_trl_dapo_v3.py", line 404, in continual_learning_main
[rank0]:     args=GRPOConfig(
[rank0]:          ~~~~~~~~~~^
[rank0]:         output_dir=f"/opt/dlami/nvme/gpt_oss/problem_{problem_idx}",
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     ...<17 lines>...
[rank0]:         generation_batch_size=1
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     ),
[rank0]:     ^
[rank0]:   File "<string>", line 175, in __init__
[rank0]:   File "/home/ubuntu/miniconda3/lib/python3.13/site-packages/trl/trainer/grpo_config.py", line 557, in __post_init__
[rank0]:     raise ValueError(
[rank0]:     ...<2 lines>...
[rank0]:     )
[rank0]: ValueError: GRPO requires at least 2 generations per prompt to calculate the advantages. You provided 1, which is less than the minimum required.
