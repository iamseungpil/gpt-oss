2025-09-05 14:07:16,355 | INFO | ðŸ“¦ Loading model: openai/gpt-oss-20b
`torch_dtype` is deprecated! Use `dtype` instead!
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
2025-09-05 14:07:18,487 | INFO | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.17s/it]
trainable params: 7,962,624 || all params: 20,922,719,808 || trainable%: 0.0381
2025-09-05 14:07:23,443 | INFO | ðŸ“Š Loaded 1 problems for continual learning
2025-09-05 14:07:23,444 | INFO | ============================================================
2025-09-05 14:07:23,444 | INFO | ðŸŽ¯ CONTINUAL LEARNING: Problem 1/10
2025-09-05 14:07:23,444 | INFO | ðŸ“‹ Problem UID: 6d75e8bb
2025-09-05 14:07:23,444 | INFO | ============================================================
2025-09-05 14:07:24,178 | INFO | ðŸŽ¯ Starting training for problem 1...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
  0%|          | 0/1 [00:00<?, ?it/s]
