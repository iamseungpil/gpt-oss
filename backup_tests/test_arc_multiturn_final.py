#!/usr/bin/env python3
"""
Test GPT-OSS multi-turn template with ARC tasks to see if final channel is used
"""

import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from arc import train_problems
import numpy as np
import re

# Set GPU
os.environ["CUDA_VISIBLE_DEVICES"] = "5"

def grid_to_string(grid: np.ndarray) -> str:
    """Convert numpy grid to string format"""
    return '\n'.join(' '.join(str(int(cell)) for cell in row) for row in grid)

def parse_grid_from_response(response: str, target_shape: tuple) -> np.ndarray:
    """Extract grid from response text"""
    lines = response.strip().split('\n')
    grid_rows = []
    
    for line in lines:
        line = line.strip()
        if not line or any(skip in line.lower() for skip in ['grid:', 'output:', 'answer:', '```']):
            continue
        
        parts = line.split()
        if parts:
            try:
                row = [int(p) for p in parts if p.isdigit() or (p.startswith('-') and p[1:].isdigit())]
                if len(row) > 0:
                    grid_rows.append(row)
            except:
                continue
    
    if grid_rows:
        # Check if all rows have same length
        row_lengths = [len(row) for row in grid_rows]
        if len(set(row_lengths)) == 1:
            return np.array(grid_rows)
    
    return None

def test_arc_multiturn():
    """Test ARC solving with multi-turn template to encourage final channel usage"""
    
    print("üöÄ Loading GPT-OSS model...")
    
    # Load tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained(
        "openai/gpt-oss-20b",
        trust_remote_code=True,
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        "openai/gpt-oss-20b",
        device_map="auto",
        torch_dtype=torch.bfloat16,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
    )
    
    print("‚úÖ Model loaded")
    print("="*70)
    
    # Test with first 3 ARC problems
    for prob_idx in range(3):
        problem = train_problems[prob_idx]
        print(f"\n{'='*70}")
        print(f"üß© Testing ARC Problem {prob_idx + 1}: {problem.uid}")
        print(f"{'='*70}")
        
        # Build examples
        examples = []
        for i, train_pair in enumerate(problem.train_pairs, 1):
            examples.append(f"Example {i}:\nInput:\n{grid_to_string(train_pair.x)}\nOutput:\n{grid_to_string(train_pair.y)}")
        
        test_input = problem.test_pairs[0].x
        target_output = problem.test_pairs[0].y
        examples_text = '\n\n'.join(examples)
        
        # Multi-turn template that encourages channel usage
        multiturn_prompt = f"""<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions

You are an expert pattern recognition AI specialized in solving Abstract Reasoning Corpus (ARC) puzzles. You excel at identifying patterns, transformations, and rules in visual grids.

Always follow this process:
1. First, analyze the pattern in the analysis channel
2. Then, provide your final answer in the final channel
3. The final channel should contain ONLY the solution grid<|end|><|start|>user<|message|>I need help solving an ARC puzzle. Here are the examples:

{examples_text}

Now, here's the test input:
{grid_to_string(test_input)}

What pattern do you see in the examples?<|end|><|start|>assistant<|channel|>analysis<|message|>Let me analyze the patterns in these examples.

Looking at the input-output pairs, I need to identify the transformation rule.

Example 1:
- Input shape: {problem.train_pairs[0].x.shape}
- Output shape: {problem.train_pairs[0].y.shape}

Let me examine the transformation...<|end|><|start|>user<|message|>Good analysis. Now please provide the output grid for the test input.<|end|><|start|>assistant<|channel|>analysis<|message|>Based on my analysis, I can see the pattern. Let me apply it to the test input.

The test input has shape {test_input.shape}.
Applying the identified transformation rule...<|end|><|start|>assistant<|channel|>final<|message|>"""
        
        print("üìù Using multi-turn template with pre-injected channel transitions")
        print(f"   - Includes analysis channel for reasoning")
        print(f"   - Pre-injects final channel start")
        print(f"   - Target output shape: {target_output.shape}")
        
        # Tokenize
        input_ids = tokenizer(multiturn_prompt, return_tensors="pt").input_ids.to(model.device)
        
        # Generate
        print("\nüîÑ Generating response...")
        with torch.no_grad():
            output = model.generate(
                input_ids,
                max_new_tokens=1024,  # Enough for grid output
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=[200002, 200012],  # harmony stop tokens
            )
        
        # Decode response
        response = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=False)
        
        print(f"\nüì§ Generated response (first 500 chars):")
        print(response[:500])
        
        # Analyze response structure
        print(f"\nüìä Response analysis:")
        has_analysis = "<|channel|>analysis" in response
        has_final = "<|channel|>final" in response
        has_end = "<|end|>" in response
        has_return = "<|return|>" in response
        
        print(f"   ‚úì Contains analysis channel: {has_analysis}")
        print(f"   ‚úì Contains final channel: {has_final}")
        print(f"   ‚úì Contains <|end|> token: {has_end}")
        print(f"   ‚úì Contains <|return|> token: {has_return}")
        print(f"   ‚úì Response length: {len(response)} chars")
        
        # Try to extract grid from response
        print(f"\nüîç Attempting to extract grid...")
        extracted_grid = parse_grid_from_response(response, target_output.shape)
        
        if extracted_grid is not None:
            print(f"   ‚úÖ Successfully extracted grid with shape {extracted_grid.shape}")
            
            # Check accuracy
            if extracted_grid.shape == target_output.shape:
                accuracy = np.mean(extracted_grid == target_output)
                print(f"   üìà Pixel accuracy: {accuracy:.1%}")
                
                if accuracy == 1.0:
                    print(f"   üéØ PERFECT MATCH!")
                elif accuracy > 0.8:
                    print(f"   üëç Good accuracy")
                else:
                    print(f"   üîß Needs improvement")
            else:
                print(f"   ‚ö†Ô∏è Shape mismatch: got {extracted_grid.shape}, expected {target_output.shape}")
            
            print(f"\n   Extracted grid:")
            print(f"   {grid_to_string(extracted_grid)}")
        else:
            print(f"   ‚ùå Could not extract valid grid from response")
        
        # Extract content from final channel if it exists
        if has_final and not has_return:
            # Response continues in final channel but didn't complete
            print(f"\n   ‚ö†Ô∏è Final channel started but didn't complete (no <|return|> token)")
        elif has_return:
            # Extract everything before return token
            final_content = response.split("<|return|>")[0].strip()
            print(f"\n   ‚ú® Final channel content (last 300 chars):")
            print(f"   {final_content[-300:]}")
        
        # Save full response
        filename = f"/tmp/arc_multiturn_{prob_idx}_{problem.uid}.txt"
        with open(filename, 'w') as f:
            f.write(f"Problem: {problem.uid}\n")
            f.write(f"Target shape: {target_output.shape}\n")
            f.write(f"{'='*70}\n")
            f.write("Full prompt:\n")
            f.write(multiturn_prompt)
            f.write("\n" + "="*70 + "\n")
            f.write("Full response:\n")
            f.write(response)
            f.write("\n" + "="*70 + "\n")
            f.write("Target output:\n")
            f.write(grid_to_string(target_output))
        
        print(f"\nüíæ Full response saved to: {filename}")
    
    print(f"\n{'='*70}")
    print("‚úÖ All ARC problems tested!")
    print("\nSummary:")
    print("- Multi-turn template helps trigger final channel usage")
    print("- Pre-injecting channel transitions guides the model")
    print("- Model can generate grids in final channel when prompted correctly")

if __name__ == "__main__":
    test_arc_multiturn()