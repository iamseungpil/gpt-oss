2025-09-02 04:55:02,109 | INFO | ðŸ“¦ Loading model: openai/gpt-oss-20b
`torch_dtype` is deprecated! Use `dtype` instead!
MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16
Loading checkpoint shards: 100%|â–ˆ| 3/3 [00:04<00:00,  1.50
trainable params: 7,962,624 || all params: 20,922,719,808 || trainable%: 0.0381
2025-09-02 04:55:13,610 | INFO | ðŸ“Š Preparing dataset...
2025-09-02 04:55:13,698 | INFO | ðŸ“Š Created dataset with 400 examples
Traceback (most recent call last):
  File "/home/ubuntu/gpt-oss/main_hf_trl_dapo_v2.py", line 507, in <module>
    main()
    ~~~~^^
  File "/home/ubuntu/gpt-oss/main_hf_trl_dapo_v2.py", line 388, in main
    grpo_config = GRPOConfig(
        output_dir=str(DATA_DIR / "checkpoints_hf_trl_dapo_v2"),
    ...<28 lines>...
        max_grad_norm=1.0,
    )
  File "<string>", line 175, in __init__
  File "/home/ubuntu/miniconda3/lib/python3.13/site-packages/trl/trainer/grpo_config.py", line 557, in __post_init__
    raise ValueError(
    ...<2 lines>...
    )
ValueError: GRPO requires at least 2 generations per prompt to calculate the advantages. You provided 1, which is less than the minimum required.
